base_model: pierreguillou/gpt2-small-portuguese
data_path: data/raw/cronicas.json
output_dir: data/samples/cronicas-lora
max_seq_length: 256
adapter_path: data/samples/cronicas-lora
max_new_tokens: 160
temperature: 0.9
top_p: 0.9

training:
  batch_size: 4
  grad_accum: 4
  warmup_steps: 50
  learning_rate: 0.0002
  epochs: 2

generation:
  max_new_tokens: 160
  temperature: 0.9
  top_p: 0.9